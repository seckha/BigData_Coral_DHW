---
title: "BEES 9041 - Coral cover and DHW in the GBR"
author: "Shannon Eckhardt"
date: '2022-07-28'
output: html_document
---

# Load libraries
```{r, echo = FALSE}
Sys.setenv(LANG = "en")
rm(list=ls()) # clear environment
# load all libraries
library(lubridate)
library(ncdf4)
library(terra)
library(sf)
library(raster)
library(tidyverse)
library(readxl)
library(here)
library(gganimate)
library(tibble)
library(plotly) # for interactive map
library(zoo)
```

# Load the DHW data
There is a DHW file for each day from 1992-2021 that has to be downloaded from the NOAA Coral Watch Website *(see other script for extraction of the files)*. The files can be found [here](https://www.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1_op/nc/v1.0/monthly/).
```{r}
# create a list of the DHW files and extract them from a folder
ncfiles <-  list.files(
  "/Users/Shannon/OneDrive/A - UNSW/T2 2022/BEES9041/BigData_Coral_DHW/Data/DHW/data", 
  pattern    = ".nc$", # load all the files with .nc at the end of the file
  full.names = TRUE)

# get the files for the summer months only -> 12 = December, 01 = January, 02 = February
# \d matches any digits
target_files <-  grep(ncfiles, pattern=r"((12|01|02)\d\d.nc$)", value=TRUE)

# extract only year-month-day from the filenames -> extract the numbers standing in front of .nc at the end of the filename
ymd <-  gsub(x = target_files, pattern=".+(\\d{8}).nc$", replacement =  "\\1")
# turn ymd into actual date format
dates <-  lubridate::ymd(ymd)

#  adjust to the extent you are after,
#  be sure it aligns with the cellsize and boundaries of the netcdf data
# CRS = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"
# crs copied from one of the netcdf files
CRS = "+proj=longlat +a=6378137 +rf=298.2572 +no_defs"

# define the area of and around the GBR and convert to an sf object
GBR_extent <-  st_as_sf(
  # convert to an sfc object
  st_as_sfc(
    st_bbox(c(xmin = 140, ymin = -9, xmax = 155, ymax = -29)),
    crs=CRS))

# create a raster where the GBR area acts as a base
GBR_base_ras <-  rast(
  GBR_extent, 
  resolution = 0.05,
  crs=CRS,
  vals=0)

means_list <-  list()
four_dhw_list <- list()
target_years <-  1992:2021
for (year in target_years) {
  sum_ras = 0 * GBR_base_ras
  four_dhw = sum_ras
  # find files where dates are in the southern hemisphere summer starting in the target year
  # start from Dec in target year -> start Dec 1992
  start_date <-  ymd(paste0(year, "1201"))
  # end in target year+1 in Feb -> end Feb 1993 to get summer 1992/1993 ->  takes 28-29 days in Feb into account
  end_date   <-  ymd(paste0(year+1, "0301"))  
  #  dates in season = dates for 1 summer season (Dec-Feb)
  dates_in_season <-  dates >= start_date & dates < end_date # from Dec 1 till Feb 29
  files_in_season <-  target_files[dates_in_season]
  #message (head (files_in_season))

  for (file in files_in_season) {
    # terra uses gdal underneath to read the file
    # and is much faster than fiddling with ncdf4 and raster libs
    # formatted = sprintf("NETCDF:%s", file)
    # r = rast(formatted)["degree_heating_week"]
    
    #  get the component we care about as a terra::rast object 
    r = rast(file)["degree_heating_week"] # degree heating week is a variable in every file containing values
    clipped <- raster::crop(r, GBR_base_ras) # subset of r where just the data from the GBR is used, not the world
    sum_ras <- sum_ras + clipped
    # message (file)
    # message (paste (summary (r)))
    
    # take out individual days which have a DHW above 4°C
    thresh <- clipped >= 4
    four_dhw <- four_dhw + thresh
    
    gc() # garbage collection
  }
  mean_ras <-  sum_ras / length(files_in_season) # mean DHW for every year = every summer season
  #  now do something with mean_ras, e.g. save it to your hard drive
  #  to process in another script
  # plot(mean_ras) # plots 30 years (summers) from 1992 - 2021
  # mean DHW per summer per location (1 value per location per year):
  means_list[[as.character(year)]] <- mean_ras
  four_dhw_list[[as.character(year)]] <- four_dhw
}
```

# Turn the lists with the rasters into a raster stack
```{r, echo = FALSE}
#  this has all the data and can be drilled into to extract the time series for each location
stack_means <- rast(means_list) # raster stack
stack_over4dhw <- rast(four_dhw_list)
# readValues(stack_means$"1993") # one year/summer has more than one value because there's multiple locations!
summary(stack_means, maxsamp = ncell(stack_means))
```

# Load the coral cover data
The coral cover data comes from the Australian Institute for Marine Science (AIMS) Long-term Monitoring Program (LTMP) in the GBR and can be found here: (AIMS LTMP)[https://apps.aims.gov.au/metadata/view/a17249ab-5316-4396-bb27-29f2d568f727]. They have been recording coral cover and other changes in reef communities since 1983, however, the coral cover data starts in 1992.

```{r}
# load metadata for manta tow (coral reefs)
corals <- read_excel("/Users/Shannon/OneDrive/A - UNSW/T2 2022/BEES9041/BigData_Coral_DHW/Data/metadata_manta_tow.xlsx")

# new column -> coral cover per unit effort (CPUE)
# new column -> dead coral cover per unit effort (DPUE)
# log transform because both variables skewed and +1 because of zeros
corals <- mutate(corals, log_cpue = log10((mean_live_coral / tows)+1))
corals <- mutate(corals, log_dpue = log10((mean_dead_coral / tows)+1))
```

# Summarize data into Northern, Central, and Southern GBR
## Sectors
### North
CG – Cape Grenville
CL – Cooktown-Lizard Island
PC – Princess Charlotte Bay
TS – Torres Strait

### Central
CA – Cairns
CU – Cape Upstart
IN - Innisfail
TO – Townsville
WH - Whitsundays

### South
CB – Capricorn-Bunker
PO - Pompey
SW – Swain

```{r}
unique(corals$sector)
n_distinct(corals$sector)
count(corals, sector)

# NORTH ------------------------------------------
cg <- filter(corals, sector == "CG")
cl <- filter(corals, sector == "CL")
pc <- filter(corals, sector == "PC")
ts <- filter(corals, sector == "TS")
northGBR <- rbind(cg, cl, pc, ts)

# use floor_date from lubridate package to round down to the year of the sample date
# not using variable report_year because that is the year the report was issued not the year it was sampled
mean_northGBR <- northGBR %>%
    group_by(sample_year = floor_date(sample_date, "year")) %>%
    summarize(mean_north = mean(log_cpue))

meandead_northGBR <- northGBR %>%
    group_by(sample_year = floor_date(sample_date, "year")) %>%
    summarize(meandead_north = mean(log_dpue))

# CENTRAL ------------------------------------------
ca <- filter(corals, sector == "CA")
cu <- filter(corals, sector == "CU")
in_ <- filter(corals, sector == "IN")
to <- filter(corals, sector == "TO")
wh <- filter(corals, sector == "WH")
centralGBR <- rbind(ca, cu, in_, to, wh)

mean_centralGBR <- centralGBR %>%
    group_by(sample_year = floor_date(sample_date, "year")) %>%
    summarize(mean_central = mean(log_cpue))

meandead_centralGBR <- centralGBR %>%
    group_by(sample_year = floor_date(sample_date, "year")) %>%
    summarize(meandead_central = mean(log_dpue))

# SOUTH ------------------------------------------
cb <- filter(corals, sector == "CB")
po <- filter(corals, sector == "PO")
sw <- filter(corals, sector == "SW")
southGBR <- rbind(cb, po, sw)

mean_southGBR <- southGBR %>%
    group_by(sample_year = floor_date(sample_date, "year")) %>%
    summarize(mean_south = mean(log_cpue))

meandead_southGBR <- southGBR %>%
    group_by(sample_year = floor_date(sample_date, "year")) %>%
    summarize(meandead_south = mean(log_dpue))

# mean coral cover
ggplot() +
  geom_point(data = mean_northGBR, aes(x = sample_year, y = mean_north), color = "red") +
  geom_line(data = mean_northGBR, aes(x = sample_year, y = mean_north), color = "red") +
  geom_point(data = mean_centralGBR, aes(x = sample_year, y = mean_central), color = "green") +
  geom_line(data = mean_centralGBR, aes(x = sample_year, y = mean_central), color = "green") +
  geom_point(data = mean_southGBR, aes(x = sample_year, y = mean_south), color = "blue") +
  geom_line(data = mean_southGBR, aes(x = sample_year, y = mean_south), color = "blue") +
  theme_classic() +
  ylab("Log(Mean Cover per Unit Effort)")

# mean dead coral cover
ggplot() +
  geom_point(data = meandead_northGBR, aes(x = sample_year, y = meandead_north), color = "red") +
  geom_line(data = meandead_northGBR, aes(x = sample_year, y = meandead_north), color = "red") +
  geom_point(data = meandead_centralGBR, aes(x = sample_year, y = meandead_central), color = "green") +
  geom_line(data = meandead_centralGBR, aes(x = sample_year, y = meandead_central), color = "green") +
  geom_point(data = meandead_southGBR, aes(x = sample_year, y = meandead_south), color = "blue") +
  geom_line(data = meandead_southGBR, aes(x = sample_year, y = meandead_south), color = "blue") +
  theme_classic() +
  ylab("Log(Mean Dead Cover per Unit Effort)")
# dead cover might not equal bleached cover because bleached ≠ dead
```

## Mean cover of the individual 12 sectors
This is a more accurate representation of coral cover, as the cover for many sectors was averaged above (into North, Central, and South GBR) and some resolution was lost.
```{r}
# Calculating the mean coral cover per unit effort for each sector ------------------------------
# Cape Grenville
mean_cg <- cg %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Cooktown-Lizard Island
mean_cl <-  cl %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Princess Charlotte Bay
mean_pc <-  pc %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Torres Strait -> only one observation in 2021
mean_ts <-  ts %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Cairns
mean_ca <-  ca %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Cape Upstart
mean_cu <-  cu %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Innisfail
mean_in <-  in_ %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Townsville
mean_to <-  to %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Whitsundays
mean_wh <-  wh %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Capricorn-Bunker
mean_cb <-  cb %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Pompey
mean_po <-  po %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Swain
mean_sw <-  sw %>%
  group_by(sample_year = floor_date(sample_date, "year")) %>%
  summarize(mean_cover = mean(log_cpue))

# Plot all of the sectors ------------------------------------------------------------------------------
# there are df where there's not continuous values from 1992-2021 because there were no manta tows for some years

# North sectors
setNames(list(mean_cg, mean_cl, mean_pc, mean_ts), c("mean_cg", "mean_cl", "mean_pc", "mean_ts")) %>%
  map_df(~ .x %>% gather(key, value, -sample_year), .id="source") %>% 
  ggplot(aes(x = sample_year, y = value, colour=source)) +
  geom_line() +
  geom_point(size = 0.75, alpha = 0.5) +
  xlab("Sample Year") +
  ylab("log(Mean Cover per Unit Effort)") +
  scale_color_brewer("", labels = c("Cape Grenville", "Cooktown-Lizard Island", "Princess Charlotte Bay", "Torres Strait"), palette = "Set2") +
  ggtitle("North Sectors") +
  theme_classic()

ggsave(filename = here("Plots/north_sectors_mean_cover.pdf"), plot = last_plot(), height = 15, width = 25, units = "cm", scale = 0.7)

# Central sectors
setNames(list(mean_ca, mean_cu, mean_in, mean_to, mean_wh), c("mean_ca", "mean_cu", "mean_in", "mean_to", "mean_wh")) %>%
  map_df(~ .x %>% gather(key, value, -sample_year), .id="source") %>% 
  ggplot(aes(x = sample_year, y = value, colour=source)) +
  geom_line() +
  geom_point(size = 0.75, alpha = 0.5) +
  xlab("Sample Year") +
  ylab("log(Mean Cover per Unit Effort)") +
  scale_color_brewer("", labels = c("Cairns", "Cape Upstart", "Innisfail", "Townsville", "Whitsundays"), palette = "Set2") +
  ggtitle("Central Sectors") +
  theme_classic()

ggsave(filename = here("Plots/central_sectors_mean_cover.pdf"), plot = last_plot(), height = 15, width = 25, units = "cm", scale = 0.7)

# South sectors
setNames(list(mean_cb, mean_po, mean_sw), c("mean_cb", "mean_po", "mean_sw")) %>%
  map_df(~ .x %>% gather(key, value, -sample_year), .id="source") %>% 
  ggplot(aes(x = sample_year, y = value, colour=source)) +
  geom_line() +
  geom_point(size = 0.75, alpha = 0.5) +
  xlab("Sample Year") +
  ylab("log(Mean Cover per Unit Effort)") +
  scale_color_brewer("", labels = c("Capricorn-Bunker", "Pompey", "Swain"), palette = "Set2") +
  ggtitle("South Sectors") +
  theme_classic()

ggsave(filename = here("Plots/south_sectors_mean_cover.pdf"), plot = last_plot(), height = 15, width = 25, units = "cm", scale = 0.7)

```

 -> color based on how north they are


# Plots of the GBR and the mean DHW for each summer 
1 value per location per summer/year
```{r}
# Convert raster to SpatialPointsDataFrame
mean_dhw_df <- as.data.frame(stack_means, xy = TRUE)

# labels for the plot titles
labelz <- c("1992", "1993","1994", "1995", "1996","1997",  "1998", "1999", "2000", "2001", "2002", "2003", "2004", "2005","2006", "2007","2008", "2009", "2010", "2011",  "2012", "2013","2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021")

# mean DHW plots for just one year
ggplot(mean_dhw_df, aes(x, y)) +
  geom_raster(aes(fill = `2021`)) +
  geom_point(data = corals, aes(x = lon, y = lat), color = "grey", size = 0.3) +
  scale_fill_viridis_c(option = "inferno") +
  coord_quickmap() +
  labs(fill = "Mean DHWs") +
  ggtitle("2021") +
  theme_classic()


# loop of plots for all the years
for (i in 3:32){
  print(ggplot(mean_dhw_df, aes(x, y)) +
    geom_raster(aes(fill = mean_dhw_df[,i, drop = TRUE])) +
    geom_point(data = northGBR, aes(lon, lat), color = "#CCCCCC", size = 0.3) +
    geom_point(data = centralGBR, aes(lon, lat), color = "#999999", size = 0.3) +
    geom_point(data = southGBR, aes(lon, lat), color = "#666666", size = 0.3) +  
    scale_fill_viridis_c(option = "inferno") +
    coord_quickmap() +
    labs(fill = "Mean DHWs [°C]") +
    ggtitle(labelz[i-2]) +
    xlab("Longitude°E") +
    ylab("Latitude°") +
    theme_classic())
}

# interactive map for one year
p <- ggplot(mean_dhw_df, aes(x, y)) +
      geom_raster(aes(fill = `2021`)) +
      geom_point(data = corals, aes(lon, lat), color = "grey", size = 0.5) +
      scale_fill_viridis_c(option = "inferno") +
      coord_quickmap() +
      labs(fill = "Mean DHWs [°C]") +
      ggtitle("2021") +
      xlab("Longitude°E") +
      ylab("Latitude°") +
      theme_classic()
 ggplotly(p)

?transition_states
 
# Animation

for (i in 3:32){
  print(ggplot(mean_dhw_df, aes(x, y)) +
    geom_raster(aes(fill = mean_dhw_df[,i, drop = TRUE])) +
    geom_point(data = northGBR, aes(lon, lat), color = "#CCCCCC", size = 0.3) +
    geom_point(data = centralGBR, aes(lon, lat), color = "#999999", size = 0.3) +
    geom_point(data = southGBR, aes(lon, lat), color = "#666666", size = 0.3) +  
    scale_fill_viridis_c(option = "inferno") +
    coord_quickmap() +
    labs(fill = "Mean DHWs [°C]") +
    ggtitle(labelz[i-2]) +
    xlab("Longitude°E") +
    ylab("Latitude°") +
    theme_classic())
  #anim_save(p, "animation_mean_dhw.gif", animation = last_animation(), renderer = gifski_renderer())
}
 
animate(p, duration = 5, fps = 20, width = 200, height = 200, renderer = gifski_renderer("test.gif"))

 
 
 
 
```


# Plots of the GBR and the >= 4 DHW --------------------------------------------------- maybe remove
Days per summer there's been equal or over 4 DHW
```{r}
# over4dhw had values of how many days in that summer were over 4 DHW
over4dhw_df <- as.data.frame(stack_over4dhw, xy = TRUE)

# plot for just one year
ggplot(over4dhw_df, aes(x, y)) +
  geom_raster(aes(fill = `2020`)) +
  geom_point(data = corals, aes(x = lon, y = lat), color = "grey", size = 0.3) +
  scale_fill_viridis_c(option = "magma") +
  coord_quickmap() +
  labs(fill = "Mean DHWs") +
  ggtitle("2020") +
  theme_classic()

# loop of plots for all the years
for (i in 3:32){
  print(ggplot(over4dhw_df, aes(x, y)) +
    geom_raster(aes(fill = over4dhw_df[,i, drop = TRUE])) +
    geom_point(data = corals, aes(lon, lat), color = "grey", size = 0.3) +
    scale_fill_viridis_c(option = "magma") +
    coord_quickmap() +
    labs(fill = "Number of days with >= 4-DHWs") +
    ggtitle(labelz[i-2]) +
    xlab("Longitude°E") +
    ylab("Latitude°") +
    theme_classic())
}

# Interactive map for one year
# to look for sites that have experienced DHW >= 4

p <- ggplot(over4dhw_df, aes(x, y)) +
      geom_raster(aes(fill = `2021`)) +
      geom_point(data = northGBR, aes(lon, lat), color = "grey", size = 0.5) +
      scale_fill_viridis_c(option = "magma") +
      coord_quickmap() +
      labs(fill = "Number of days with >= 4-DHWs") +
      ggtitle("2021") +
      xlab("Longitude°E") +
      ylab("Latitude°") +
      theme_classic()
 ggplotly(p)

# Animation
# not work
for (i in 3:32){
  ggplot(over4dhw_df, aes(x, y)) +
    geom_raster(aes(fill = over4dhw_df[,i, drop = TRUE])) +
    scale_fill_viridis_c(option = "magma") +
    coord_quickmap() +
    labs(fill = "Number of days with >= 4-DHWs") +
    ggtitle(labelz[i-2]) +
    xlab("Longitude°E") +
    ylab("Latitude°") +
    theme_classic() +
    transition_manual(over4dhw_df[,i])
}
 
 
 
 
```
# Choose coral reef locations
Choose coral reef location based on how many data points (rows) there are. How many rows there is directly corresponds to how many times the reef was sampled. Choose 10 locations distributed along the GBR.


```{r}
# there is data from 1992 - 2021 for some locations, i.e. with the most amount of data points

# count the number of times the reef_id appears in the dataframe
tt <- table(corals$reef_id)

# tt > 20 -> looks at which reef id's appear more than 20 times
# tt[tt > 20] -> from the table select which reef id's appear more than 20 times
# names(tt[tt > 20]) -> gets their names = reef id's
# corals$reef_id %in% names(tt[tt > 20]) -> rows of reef_id that matches the > 20 reef_id appearances
# FALSE rows removed, TRUE rows kept

# North GBR -----------------------------------------------------
north_select <- northGBR[northGBR$reef_id %in% names(tt[tt > 18]),]
n_distinct(north_select$reef_id)

# MACGILLIVRAY REEF (25 obs) -> not NO NAME REEF because it is right next to mac reef (-14.65) (CL)
# BOULDER REEF (20 obs) -> -15.41667 (CL)
# 13124S (19 obs) -> -13.86667
# 2 in CL, but if I go any lower than that there's basically no data points left

# pick the north reef out that will be analyzed -> MACGILLIVRAY REEF
n_macgillivray <- filter(north_select, reef_name == "MACGILLIVRAY REEF")
n_13124S <- filter(north_select, reef_name == "13124S")
n_boulder <- filter(north_select, reef_name == "BOULDER REEF")

# Central GBR ------------------------------------------------
central_select <- centralGBR[centralGBR$reef_id %in% names(tt[tt > 22]),]
n_distinct(central_select$reef_id)

# AGINCOURT REEFS (NO 1) (28 obs) -> -16.05000 (Cairns)
# FEATHER REEF (25 obs) -> -17.53333	(Innisfail)
# RIB REEF (28 obs) -> -18.48333 (Townsville)
# 19138S (23 obs) -> -19.80833	(Whitsundays)

c_agincourt <- filter(central_select, reef_name == "AGINCOURT REEFS (NO 1)")
c_feather <- filter(central_select, reef_name == "FEATHER REEF")
c_rib <- filter(central_select, reef_name == "RIB REEF")
c_19138S <- filter(central_select, reef_name == "19138S")

# South GBR -----------------------------------
south_select <- southGBR[southGBR$reef_id %in% names(tt[tt > 20]),]
n_distinct(south_select$reef_id)
unique(south_select$reef_name)
# CHINAMAN REEF(22102) (28 obs) -> -22.00833 (SW)
# BROOMFIELD REEF (27 obs) -> -23.27500 (CB)
# CREDLIN REEFS (EAST) (21 obs) -> -20.54167	(PO)

s_chinaman <- filter(south_select, reef_name == "CHINAMAN REEF(22102)")
s_broomfield <- filter(south_select, reef_name == "BROOMFIELD REEF")
s_credlin <- filter(south_select, reef_name == "CREDLIN REEFS (EAST)")
```

# Link mean DHW and coral data
Get the DHWs for the specific reef locations chosen above: north_reef, central_reef, and south_reef. This will then give me the time series data I need. The 10 reef locations I have:
North GBR: *MACGILLIVRAY REEF* (25 obs), *BOULDER REEF* (20 obs), *13124S* (19 obs)
Central GBR: *AGINCOURT REEFS (NO 1)* (28 obs), *FEATHER REEF* (25 obs), *RIB REEF* (28 obs), *19138S* (23 obs)
South GBR: *CHINAMAN REEF(22102)* (28 obs), *BROOMFIELD REEF* (27 obs), *CREDLIN REEFS (EAST)* (21 obs)
```{r}
# extract() -> extract values from a SpatRaster for a set of locations
  # lon,lat -> in that order
  # specify that lon and lat come from a data frame, not a vector or a matrix
  # xy = TRUE to keep lon and lat (don't need them in TS, but I need them for statistics)
ex_macgillivray <- terra::extract(stack_means, data.frame(n_macgillivray$lon, n_macgillivray$lat))
ex_macgillivray_xy <- terra::extract(stack_means, data.frame(n_macgillivray$lon, n_macgillivray$lat), xy = TRUE)

ex_boulder <- terra::extract(stack_means, data.frame(n_boulder$lon, n_boulder$lat))
ex_boulder_xy <- terra::extract(stack_means, data.frame(n_boulder$lon, n_boulder$lat), xy = TRUE)

ex_13124S <- terra::extract(stack_means, data.frame(n_13124S$lon, n_13124S$lat))
ex_13124S_xy <- terra::extract(stack_means, data.frame(n_13124S$lon, n_13124S$lat), xy = TRUE)


ex_agincourt <- terra::extract(stack_means, data.frame(c_agincourt$lon, c_agincourt$lat))
ex_agincourt_xy <- terra::extract(stack_means, data.frame(c_agincourt$lon, c_agincourt$lat), xy = TRUE)

ex_feather <- terra::extract(stack_means, data.frame(c_feather$lon, c_feather$lat))
ex_feather_xy <- terra::extract(stack_means, data.frame(c_feather$lon, c_feather$lat), xy = TRUE)

ex_rib <- terra::extract(stack_means, data.frame(c_rib$lon, c_rib$lat))
ex_rib_xy <- terra::extract(stack_means, data.frame(c_rib$lon, c_rib$lat), xy = TRUE)

ex_19138S <- terra::extract(stack_means, data.frame(c_19138S$lon, c_19138S$lat))
ex_19138S_xy <- terra::extract(stack_means, data.frame(c_19138S$lon, c_19138S$lat), xy = TRUE)


ex_chinaman <- terra::extract(stack_means, data.frame(s_chinaman$lon, s_chinaman$lat))
ex_chinaman_xy <- terra::extract(stack_means, data.frame(s_chinaman$lon, s_chinaman$lat), xy = TRUE)

ex_broomfield <- terra::extract(stack_means, data.frame(s_broomfield$lon, s_broomfield$lat))
ex_broomfield_xy <- terra::extract(stack_means, data.frame(s_broomfield$lon, s_broomfield$lat), xy = TRUE)

ex_credlin <- terra::extract(stack_means, data.frame(s_credlin$lon, s_credlin$lat))
ex_credlin_xy <- terra::extract(stack_means, data.frame(s_credlin$lon, s_credlin$lat), xy = TRUE)
```

## Rename the columns and turn them into dates to use for the time series
```{r}
extracts_list <- list(ex_macgillivray, ex_boulder, ex_13124S, ex_agincourt, ex_feather, ex_rib, ex_19138S, ex_chinaman, ex_broomfield, ex_credlin)

names(extracts_list) <- c("Macgillivray Reef", "Boulder Reef", "13124S", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S","Chinaman Reef", "Broomfield Reef", "Credlin Reefs (east)")

for (i in 1:length(extracts_list)){
  # get rid of first column called ID
  extracts_list[[i]] <- select(extracts_list[[i]], -"ID")
  # select one row (because all lines contain the same values) and transpose
  extracts_list[[i]] <- extracts_list[[i]][1,]
  # transpose
  extracts_list[[i]] <- as.data.frame(t(extracts_list[[i]]))
  # turn first row names (years) into a column and call the column "year"
  extracts_list[[i]] <- tibble::rownames_to_column(extracts_list[[i]], "year")
  # name the second column "mean_dhw"
  names(extracts_list[[i]])[2] <- "mean_dhw"
  # convert the year <chr> into a date
  extracts_list[[i]][1]$year <- ymd(sprintf("%s-01-01", extracts_list[[i]][1]$year))
}
# I now have all the coral sites with year and mean dhw in a list
```

# Time Series Analysis
```{r}
# zoo time series for mean DHW at all locations
zoo_list_dhw <- list()
for (i in 1:length(extracts_list)){
  name <- paste0(names(extracts_list[i]))
  zoo_list_dhw[[name]] <- zoo(extracts_list[[i]][,2], order.by = extracts_list[[i]][,1], frequency = 1)
  plot.zoo(zoo_list_dhw[[name]], ylab = "Mean DHW", xlab = "Years") + title(main = names(zoo_list_dhw[i]))
}

# zoo time series for log_cpue at all locations
cpue_list <- list(n_macgillivray, n_boulder, n_13124S, c_agincourt, c_feather, c_rib, c_19138S, s_chinaman, s_broomfield, s_credlin)

names(cpue_list) <- c("Macgillivray Reef", "Boulder Reef", "13124S", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S","Chinaman Reef", "Broomfield Reef", "Credlin Reefs (east)")

zoo_list_cpue <- list()
cpue_list_ggplot <- list()
for (i in 1:length(cpue_list)){
  name <- paste0(names(cpue_list[i]))
  zoo_list_cpue[[name]] <- zoo(cpue_list[[i]]$log_cpue, order.by = cpue_list[[i]]$sample_date, frequency = 1)
  #plot.zoo(zoo_list_cpue[[name]], ylab = "Mean DHW", xlab = "Years") + title(main = names(zoo_list_cpue[i]))
  # convert zoo object into data frame to use ggplot
  cpue_list_ggplot[[name]] <- fortify(zoo_list_cpue[[i]], melt = FALSE)
  # rename columns
  names(cpue_list_ggplot[[i]])[1] <- "years"
  names(cpue_list_ggplot[[i]])[2] <- "log_cpue"
  # new column with list name so that I can put data frames together and know where they came from
  cpue_list_ggplot[[i]]$site <- names(cpue_list_ggplot[i])
  # for facet_wrapping put all data frames into one
}

cpue_ts_plots <- do.call(rbind,cpue_list_ggplot)

ggplot(cpue_ts_plots, aes(x = years, y = log_cpue, color = factor(site, levels = c( "13124S", "Macgillivray Reef", "Boulder Reef", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S", "Credlin Reefs (east)", "Chinaman Reef", "Broomfield Reef")))) +
  geom_point() +
  geom_line() +
  ylab("Log(Mean Cover per Unit Effort)") +
  xlab("Years") +
  theme_classic() +
  theme(legend.position = "none") +
  facet_wrap(~factor(site, levels = c( "13124S", "Macgillivray Reef", "Boulder Reef", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S", "Credlin Reefs (east)", "Chinaman Reef", "Broomfield Reef")), ncol = 1) +
  scale_color_viridis_d(option = "magma") +
  scale_x_date(date_breaks = "1 year")
```


 