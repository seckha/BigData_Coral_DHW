---
title: "BEES 9041 - Coral cover and DHW in the GBR"
author: "Shannon Eckhardt"
date: '2022-07-28'
output: html_document
---

# Load libraries
```{r, echo = FALSE}
Sys.setenv(LANG = "en")
rm(list=ls()) # clear environment
# load all libraries
library(lubridate)
library(ncdf4)
library(terra)
library(sf)
library(raster)
library(tidyverse)
library(readxl)
library(here)
library(tibble)
library(plotly) # for interactive map
library(zoo) # for time series object with non-regular intervals
library(forecast) # for cross-correlation
library(ggfortify) # for autoplot
library(lmtest) # for Durbin-Watson test
library(orcutt) # to account for autocorrelation
```

# Load the DHW data
There is a DHW file for each day from 1992-2021 that has to be downloaded from the NOAA Coral Watch Website *(see other script for extraction of the files)*. The files can be found [here](https://www.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1_op/nc/v1.0/monthly/).
```{r}
# create a list of the DHW files and extract them from a folder
ncfiles <-  list.files(
  "/Users/Shannon/OneDrive/A - UNSW/T2 2022/BEES9041/BigData_Coral_DHW/Data/DHW/data", 
  pattern    = ".nc$", # load all the files with .nc at the end of the file
  full.names = TRUE)

# get the files for the summer months only -> 12 = December, 01 = January, 02 = February
# \d matches any digits
target_files <-  grep(ncfiles, pattern=r"((12|01|02)\d\d.nc$)", value=TRUE)

# extract only year-month-day from the filenames -> extract the numbers standing in front of .nc at the end of the filename
ymd <-  gsub(x = target_files, pattern=".+(\\d{8}).nc$", replacement =  "\\1")
# turn ymd into actual date format
dates <-  lubridate::ymd(ymd)

#  adjust to the extent you are after,
#  be sure it aligns with the cellsize and boundaries of the netcdf data
# CRS = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"
# crs copied from one of the netcdf files
CRS = "+proj=longlat +a=6378137 +rf=298.2572 +no_defs"

# define the area of and around the GBR and convert to an sf object
GBR_extent <-  st_as_sf(
  # convert to an sfc object
  st_as_sfc(
    st_bbox(c(xmin = 140, ymin = -9, xmax = 155, ymax = -29)),
    crs=CRS))

# create a raster where the GBR area acts as a base
GBR_base_ras <-  rast(
  GBR_extent, 
  resolution = 0.05,
  crs=CRS,
  vals=0)

means_list <-  list()
# four_dhw_list <- list()
target_years <-  1992:2021
for (year in target_years) {
  sum_ras = 0 * GBR_base_ras
  # four_dhw = sum_ras
  # find files where dates are in the southern hemisphere summer starting in the target year
  # start from Dec in target year -> start Dec 1992
  start_date <-  ymd(paste0(year, "1201"))
  # end in target year+1 in Feb -> end Feb 1993 to get summer 1992/1993 ->  takes 28-29 days in Feb into account
  end_date   <-  ymd(paste0(year+1, "0301"))  
  #  dates in season = dates for 1 summer season (Dec-Feb)
  dates_in_season <-  dates >= start_date & dates < end_date # from Dec 1 till Feb 29
  files_in_season <-  target_files[dates_in_season]

  for (file in files_in_season) {
    #  get the component we care about as a terra::rast object 
    r = rast(file)["degree_heating_week"] # degree heating week is a variable in every file containing values
    clipped <- raster::crop(r, GBR_base_ras) # subset of r where just the data from the GBR is used, not the world
    sum_ras <- sum_ras + clipped
    
    # take out individual days which have a DHW above 4°C
    #thresh <- clipped >= 4
    #four_dhw <- four_dhw + thresh
    
    gc() # garbage collection
  }
  mean_ras <-  sum_ras / length(files_in_season) # mean DHW for every year = every summer season
  #  now do something with mean_ras, e.g. save it to your hard drive
  #  to process in another script
  # plot(mean_ras) # plots 30 years (summers) from 1992 - 2021
  # mean DHW per summer per location (1 value per location per year):
  means_list[[as.character(year)]] <- mean_ras
  #four_dhw_list[[as.character(year)]] <- four_dhw
}
```

# Turn the lists with the rasters into a raster stack
```{r, echo = FALSE}
#  this has all the data and can be drilled into to extract the time series for each location
stack_means <- rast(means_list) # raster stack
# stack_over4dhw <- rast(four_dhw_list)
# readValues(stack_means$"1993") # one year/summer has more than one value because there's multiple locations!
# summary(stack_means, maxsamp = ncell(stack_means))
```

# Load the coral cover data
The coral cover data comes from the Australian Institute for Marine Science (AIMS) Long-term Monitoring Program (LTMP) in the GBR and can be found here: (AIMS LTMP)[https://apps.aims.gov.au/metadata/view/a17249ab-5316-4396-bb27-29f2d568f727]. They have been recording coral cover and other changes in reef communities since 1983, however, the coral cover data starts in 1992.

```{r}
# load metadata for manta tow (coral reefs)
corals <- read_excel("/Users/Shannon/OneDrive/A - UNSW/T2 2022/BEES9041/BigData_Coral_DHW/Data/metadata_manta_tow.xlsx")

# new column -> coral cover per unit effort (CPUE)
# new column -> dead coral cover per unit effort (DPUE)
# log transform because both variables skewed and +1 because of zeros
corals <- mutate(corals, log_cpue = log10((mean_live_coral / tows)+1))
corals <- mutate(corals, log_dpue = log10((mean_dead_coral / tows)+1))
corals <- mutate(corals, cpue = mean_live_coral/tows)
corals <- mutate(corals, dpue = mean_dead_coral/tows)


corals <- mutate(corals, log_cots_pertow = log10((mean_cots_per_tow /tows)+1))
corals <- mutate(corals, log_trout_pertow = log10((mean_trout_per_tow /tows)+1))
```

# Summarize data into Northern, Central, and Southern GBR
## Sectors
### North
CG – Cape Grenville
CL – Cooktown-Lizard Island
PC – Princess Charlotte Bay
TS – Torres Strait

### Central
CA – Cairns
CU – Cape Upstart
IN - Innisfail
TO – Townsville
WH - Whitsundays

### South
CB – Capricorn-Bunker
PO - Pompey
SW – Swain

```{r}
unique(corals$sector)
n_distinct(corals$sector)
count(corals, sector)

# NORTH ------------------------------------------
cg <- filter(corals, sector == "CG")
cl <- filter(corals, sector == "CL")
pc <- filter(corals, sector == "PC")
ts <- filter(corals, sector == "TS")
northGBR <- rbind(cg, cl, pc, ts)

# use floor_date from lubridate package to round down to the year of the sample date
# not using variable report_year because that is the year the report was issued not the year it was sampled
mean_northGBR <- northGBR %>%
    group_by(sample_year = round_date(sample_date, "year")) %>%
    summarize(mean_cpue = mean(cpue), 
              mean_cots = mean(mean_cots_per_tow),
              mean_trout = mean(mean_trout_per_tow),
              mean_dpue = mean(dpue))

ggplot(mean_northGBR, aes(x = sample_year)) +
  geom_line(aes(y= mean_cpue)) +
  geom_line(aes(y = mean_cots), color = "red") +
  geom_line(aes(y = mean_trout), color = "blue") +
  geom_line(aes(y = mean_dpue), color = "orange") +
  theme_classic()
  
# CENTRAL ------------------------------------------
ca <- filter(corals, sector == "CA")
cu <- filter(corals, sector == "CU")
in_ <- filter(corals, sector == "IN")
to <- filter(corals, sector == "TO")
wh <- filter(corals, sector == "WH")
centralGBR <- rbind(ca, cu, in_, to, wh)

mean_centralGBR <- centralGBR %>%
    group_by(sample_year = round_date(sample_date, "year")) %>%
    summarize(mean_cpue = mean(cpue), 
              mean_cots = mean(mean_cots_per_tow),
              mean_trout = mean(mean_trout_per_tow),
              mean_dpue= mean(dpue))

ggplot(mean_centralGBR, aes(x = sample_year)) +
  geom_line(aes(y= mean_cpue)) +
  geom_line(aes(y = mean_cots), color = "red") +
  geom_line(aes(y = mean_trout), color = "blue") +
  geom_line(aes(y = mean_dpue), color = "orange") +
  theme_classic()

# SOUTH ------------------------------------------
cb <- filter(corals, sector == "CB")
po <- filter(corals, sector == "PO")
sw <- filter(corals, sector == "SW")
southGBR <- rbind(cb, po, sw)

mean_southGBR <- southGBR %>%
    group_by(sample_year = round_date(sample_date, "year")) %>%
    summarize(mean_cpue = mean(cpue), 
              mean_cots = mean(mean_cots_per_tow),
              mean_trout = mean(mean_trout_per_tow),
              mean_dpue = mean(dpue))

ggplot(mean_southGBR, aes(x = sample_year)) +
  geom_line(aes(y= mean_cpue)) +
  geom_line(aes(y = mean_cots), color = "red") +
  geom_line(aes(y = mean_trout), color = "blue") +
  geom_line(aes(y = mean_dpue), color = "orange") +
  theme_classic()

# ALL GBR -------------------------------------------
ggplot(NULL, aes(x = sample_year, y = mean_cpue)) +
  geom_line(data = mean_northGBR, color = "red") +
  geom_line(data = mean_centralGBR, color = "green") +
  geom_line(data = mean_southGBR, color = "blue") +
  theme_classic() +
  ylab("Mean Cover per Unit Effort")

```

## Mean cover of the individual 12 sectors
This is a more accurate representation of coral cover, as the cover for many sectors was averaged above (into North, Central, and South GBR) and some resolution was lost.
```{r}
# Calculating the mean coral cover per unit effort for each sector ------------------------------
# Cape Grenville
mean_cg <- cg %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Cooktown-Lizard Island
mean_cl <-  cl %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Princess Charlotte Bay
mean_pc <-  pc %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Torres Strait -> only one observation in 2021
mean_ts <-  ts %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Cairns
mean_ca <-  ca %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Cape Upstart
mean_cu <-  cu %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Innisfail
mean_in <-  in_ %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Townsville
mean_to <-  to %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Whitsundays
mean_wh <-  wh %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Capricorn-Bunker
mean_cb <-  cb %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Pompey
mean_po <-  po %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Swain
mean_sw <-  sw %>%
  group_by(sample_year = round_date(sample_date, "year")) %>%
  summarize(mean_cpue = mean(cpue))

# Plot all of the sectors ------------------------------------------------------------------------------
# there are df where there's not continuous values from 1992-2021 because there were no manta tows for some years

# North sectors
p <- setNames(list(mean_cg, mean_cl, mean_pc, mean_ts), c("mean_cg", "mean_cl", "mean_pc", "mean_ts")) %>%
  map_df(~ .x %>% gather(key, value, -sample_year), .id="source") %>% 
  ggplot(aes(x = sample_year, y = value, colour=source)) +
  geom_line() +
  geom_point(size = 0.75, alpha = 0.5) +
  xlab("Sample Year") +
  ylab("Mean Cover per Unit Effort") +
  scale_color_brewer("", labels = c("Cape Grenville", "Cooktown-Lizard Island", "Princess Charlotte Bay", "Torres Strait"), palette = "Set2") +
  ggtitle("North Sectors") +
  theme_classic()

ggsave(p, filename = here("Plots/north_sectors_mean_cover_nolog.png"), height = 15, width = 25, units = "cm", scale = 0.7)

# Central sectors
p <- setNames(list(mean_ca, mean_cu, mean_in, mean_to, mean_wh), c("mean_ca", "mean_cu", "mean_in", "mean_to", "mean_wh")) %>%
  map_df(~ .x %>% gather(key, value, -sample_year), .id="source") %>% 
  ggplot(aes(x = sample_year, y = value, colour=source)) +
  geom_line() +
  geom_point(size = 0.75, alpha = 0.5) +
  xlab("Sample Year") +
  ylab("Mean Cover per Unit Effort") +
  scale_color_brewer("", labels = c("Cairns", "Cape Upstart", "Innisfail", "Townsville", "Whitsundays"), palette = "Set2") +
  ggtitle("Central Sectors") +
  theme_classic()

ggsave(p, filename = here("Plots/central_sectors_mean_cover_nolog.png"), height = 15, width = 25, units = "cm", scale = 0.7)

# South sectors
p <- setNames(list(mean_cb, mean_po, mean_sw), c("mean_cb", "mean_po", "mean_sw")) %>%
  map_df(~ .x %>% gather(key, value, -sample_year), .id="source") %>% 
  ggplot(aes(x = sample_year, y = value, colour=source)) +
  geom_line() +
  geom_point(size = 0.75, alpha = 0.5) +
  xlab("Sample Year") +
  ylab("Mean Cover per Unit Effort") +
  scale_color_brewer("", labels = c("Capricorn-Bunker", "Pompey", "Swain"), palette = "Set2") +
  ggtitle("South Sectors") +
  theme_classic()

ggsave(p, filename = here("Plots/south_sectors_mean_cover_nolog.png"), height = 15, width = 25, units = "cm", scale = 0.7)

```


# Plots of the GBR and the mean DHW for each summer 
1 value per location per summer/year
```{r}
# Convert raster to SpatialPointsDataFrame
mean_dhw_df <- as.data.frame(stack_means, xy = TRUE)

# labels for the plot titles
labelz <- c("1992/93", "1993/94","1994/95", "1995/96", "1996/97","1997/98",  "1998/99", "1999/00", "2000/01", "2001/02", "2002/03", "2003/04", "2004/05", "2005/06","2006/07", "2007/08","2008/09", "2009/10", "2010/11", "2011/12",  "2012/13", "2013/14","2014/15", "2015/16", "2016/17", "2017/18", "2018/19", "2019/20", "2020/21", "2021/22")

# mean DHW plots for just one year
ggplot(mean_dhw_df, aes(x, y)) +
  geom_raster(aes(fill = `2021`)) +
  geom_point(data = corals, aes(x = lon, y = lat), color = "grey", size = 0.3) +
  scale_fill_viridis_c(option = "inferno") +
  coord_quickmap() +
  labs(fill = "Mean DHWs") +
  ggtitle("2021") +
  theme_classic()

# loop of plots for all the years
for (i in 3:32){
  p <- ggplot(mean_dhw_df, aes(x, y)) +
    geom_raster(aes(fill = mean_dhw_df[,i, drop = TRUE])) +
    geom_point(data = northGBR, aes(lon, lat), color = "#CCCCCC", size = 0.3) +
    geom_point(data = centralGBR, aes(lon, lat), color = "#999999", size = 0.3) +
    geom_point(data = southGBR, aes(lon, lat), color = "#666666", size = 0.3) +  
    scale_fill_viridis_c(option = "inferno", limits = c(0,11)) +
    coord_quickmap() +
    labs(fill = "Mean DHW") +
    ggtitle(labelz[i-2]) +
    xlab("Longitude°E") +
    ylab("Latitude°") +
    theme_classic() +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
  ggsave(p, filename = paste0(names(mean_dhw_df[i]), ".png"), path = here("Plots"))
}

# all plots saved and then animate to .gif in photoshop

# interactive map for one year
p <- ggplot(mean_dhw_df, aes(x, y)) +
      geom_raster(aes(fill = `2021`)) +
      geom_point(data = corals, aes(lon, lat), color = "grey", size = 0.5) +
      scale_fill_viridis_c(option = "inferno") +
      coord_quickmap() +
      labs(fill = "Mean DHW") +
      ggtitle("2021") +
      xlab("Longitude°E") +
      ylab("Latitude°") +
      theme_classic()
 ggplotly(p)
```


# Plots of the GBR and the >= 4 DHW --------------------------------------------------- maybe remove
Days per summer there's been equal or over 4 DHW
```{r}
# over4dhw had values of how many days in that summer were over 4 DHW
over4dhw_df <- as.data.frame(stack_over4dhw, xy = TRUE)

# plot for just one year
ggplot(over4dhw_df, aes(x, y)) +
  geom_raster(aes(fill = `2020`)) +
  geom_point(data = corals, aes(x = lon, y = lat), color = "grey", size = 0.3) +
  scale_fill_viridis_c(option = "magma") +
  coord_quickmap() +
  labs(fill = "Mean DHWs") +
  ggtitle("2020") +
  theme_classic()

# loop of plots for all the years
for (i in 3:32){
  print(ggplot(over4dhw_df, aes(x, y)) +
    geom_raster(aes(fill = over4dhw_df[,i, drop = TRUE])) +
    geom_point(data = corals, aes(lon, lat), color = "grey", size = 0.3) +
    scale_fill_viridis_c(option = "magma") +
    coord_quickmap() +
    labs(fill = "Number of days with >= 4-DHWs") +
    ggtitle(labelz[i-2]) +
    xlab("Longitude°E") +
    ylab("Latitude°") +
    theme_classic())
}

# Interactive map for one year
# to look for sites that have experienced DHW >= 4

p <- ggplot(over4dhw_df, aes(x, y)) +
      geom_raster(aes(fill = `2021`)) +
      geom_point(data = northGBR, aes(lon, lat), color = "grey", size = 0.5) +
      scale_fill_viridis_c(option = "magma") +
      coord_quickmap() +
      labs(fill = "Number of days with >= 4-DHWs") +
      ggtitle("2021") +
      xlab("Longitude°E") +
      ylab("Latitude°") +
      theme_classic()
 ggplotly(p)

# Animation
# not work
for (i in 3:32){
  ggplot(over4dhw_df, aes(x, y)) +
    geom_raster(aes(fill = over4dhw_df[,i, drop = TRUE])) +
    scale_fill_viridis_c(option = "magma") +
    coord_quickmap() +
    labs(fill = "Number of days with >= 4-DHWs") +
    ggtitle(labelz[i-2]) +
    xlab("Longitude°E") +
    ylab("Latitude°") +
    theme_classic() +
    transition_manual(over4dhw_df[,i])
}
 
 
 
 
```
# Choose coral reef locations
Choose coral reef location based on how many data points (rows) there are. How many rows there is directly corresponds to how many times the reef was sampled. Choose 10 locations distributed along the GBR.


```{r}
# there is data from 1992 - 2021 for some locations, i.e. with the most amount of data points

# count the number of times the reef_id appears in the dataframe
tt <- table(corals$reef_id)

# tt > 20 -> looks at which reef id's appear more than 20 times
# tt[tt > 20] -> from the table select which reef id's appear more than 20 times
# names(tt[tt > 20]) -> gets their names = reef id's
# corals$reef_id %in% names(tt[tt > 20]) -> rows of reef_id that matches the > 20 reef_id appearances
# FALSE rows removed, TRUE rows kept

# North GBR -----------------------------------------------------
north_select <- northGBR[northGBR$reef_id %in% names(tt[tt > 18]),]
n_distinct(north_select$reef_id)

# MACGILLIVRAY REEF (25 obs) -> not NO NAME REEF because it is right next to mac reef (-14.65) (CL)
# BOULDER REEF (20 obs) -> -15.41667 (CL)
# 13124S (19 obs) -> -13.86667
# 2 in CL, but if I go any lower than that there's basically no data points left

# pick the north reef out that will be analyzed -> MACGILLIVRAY REEF
n_macgillivray <- filter(north_select, reef_name == "MACGILLIVRAY REEF")
n_13124S <- filter(north_select, reef_name == "13124S")
n_boulder <- filter(north_select, reef_name == "BOULDER REEF")

# Central GBR ------------------------------------------------
central_select <- centralGBR[centralGBR$reef_id %in% names(tt[tt > 22]),]
n_distinct(central_select$reef_id)

# AGINCOURT REEFS (NO 1) (28 obs) -> -16.05000 (Cairns)
# FEATHER REEF (25 obs) -> -17.53333	(Innisfail)
# RIB REEF (28 obs) -> -18.48333 (Townsville)
# 19138S (23 obs) -> -19.80833	(Whitsundays)

c_agincourt <- filter(central_select, reef_name == "AGINCOURT REEFS (NO 1)")
c_feather <- filter(central_select, reef_name == "FEATHER REEF")
c_rib <- filter(central_select, reef_name == "RIB REEF")
c_19138S <- filter(central_select, reef_name == "19138S")

# South GBR -----------------------------------
south_select <- southGBR[southGBR$reef_id %in% names(tt[tt > 20]),]
n_distinct(south_select$reef_id)
unique(south_select$reef_name)
# CHINAMAN REEF(22102) (28 obs) -> -22.00833 (SW)
# BROOMFIELD REEF (27 obs) -> -23.27500 (CB)
# CREDLIN REEFS (EAST) (21 obs) -> -20.54167	(PO)

s_chinaman <- filter(south_select, reef_name == "CHINAMAN REEF(22102)")
s_broomfield <- filter(south_select, reef_name == "BROOMFIELD REEF")
s_credlin <- filter(south_select, reef_name == "CREDLIN REEFS (EAST)")

world <- map_data("world")

# map with all 10 locations
p <- ggplot() +
  geom_map(data = world, map = world, aes(long, lat, map_id = region), color = "black", fill = "lightgrey", size = 0.1) +
  geom_point(data = n_13124S, aes(x = lon, y = lat), size = 1.5, color = "#440154FF") +
  geom_point(data = n_macgillivray, aes(x = lon, y = lat), size = 1.5, color = "#482677FF") + 
  geom_point(data = n_boulder, aes(x = lon, y = lat), size = 1.5, color = "#404788FF") + 
  geom_point(data = c_agincourt, aes(x = lon, y = lat), size = 1.5, color = "#404788FF") + 
  geom_point(data = c_feather, aes(x = lon, y = lat), size = 1.5, color = "#2D708EFF") + 
  geom_point(data = c_rib, aes(x = lon, y = lat), size = 1.5, color = "#238A8DFF") + 
  geom_point(data = c_19138S, aes(x = lon, y = lat), size = 1.5, color = "#20A387FF") +
  geom_point(data = s_credlin, aes(x = lon, y = lat), size = 1.5, color = "#55C667FF") + 
  geom_point(data = s_chinaman, aes(x = lon, y = lat), size = 1.5, color = "#B8DE29FF") + 
  geom_point(data = s_broomfield, aes(x = lon, y = lat), size = 1.5, color = "#FDE725FF") + 
  coord_quickmap() +
  theme_classic() +
  xlab("Longitude°E") +
  ylab("Latitude°") +
  xlim(140, 155) +
  ylim(-30, -9)

ggsave(p, filename = here("Plots/10_locations_map.png"))
```

# Link mean DHW and coral data
Get the DHWs for the specific reef locations chosen above: north_reef, central_reef, and south_reef. This will then give me the time series data I need. The 10 reef locations I have:
North GBR: *MACGILLIVRAY REEF* (25 obs), *BOULDER REEF* (20 obs), *13124S* (19 obs)
Central GBR: *AGINCOURT REEFS (NO 1)* (28 obs), *FEATHER REEF* (25 obs), *RIB REEF* (28 obs), *19138S* (23 obs)
South GBR: *CHINAMAN REEF(22102)* (28 obs), *BROOMFIELD REEF* (27 obs), *CREDLIN REEFS (EAST)* (21 obs)
```{r}
# extract() -> extract values from a SpatRaster for a set of locations
  # lon,lat -> in that order
  # specify that lon and lat come from a data frame, not a vector or a matrix
  # xy = TRUE to keep lon and lat (don't need them in TS, but I need them for statistics)
ex_macgillivray <- terra::extract(stack_means, data.frame(n_macgillivray$lon, n_macgillivray$lat))
ex_macgillivray_xy <- terra::extract(stack_means, data.frame(n_macgillivray$lon, n_macgillivray$lat), xy = TRUE)

ex_boulder <- terra::extract(stack_means, data.frame(n_boulder$lon, n_boulder$lat))
ex_boulder_xy <- terra::extract(stack_means, data.frame(n_boulder$lon, n_boulder$lat), xy = TRUE)

ex_13124S <- terra::extract(stack_means, data.frame(n_13124S$lon, n_13124S$lat))
ex_13124S_xy <- terra::extract(stack_means, data.frame(n_13124S$lon, n_13124S$lat), xy = TRUE)


ex_agincourt <- terra::extract(stack_means, data.frame(c_agincourt$lon, c_agincourt$lat))
ex_agincourt_xy <- terra::extract(stack_means, data.frame(c_agincourt$lon, c_agincourt$lat), xy = TRUE)

ex_feather <- terra::extract(stack_means, data.frame(c_feather$lon, c_feather$lat))
ex_feather_xy <- terra::extract(stack_means, data.frame(c_feather$lon, c_feather$lat), xy = TRUE)

ex_rib <- terra::extract(stack_means, data.frame(c_rib$lon, c_rib$lat))
ex_rib_xy <- terra::extract(stack_means, data.frame(c_rib$lon, c_rib$lat), xy = TRUE)

ex_19138S <- terra::extract(stack_means, data.frame(c_19138S$lon, c_19138S$lat))
ex_19138S_xy <- terra::extract(stack_means, data.frame(c_19138S$lon, c_19138S$lat), xy = TRUE)


ex_chinaman <- terra::extract(stack_means, data.frame(s_chinaman$lon, s_chinaman$lat))
ex_chinaman_xy <- terra::extract(stack_means, data.frame(s_chinaman$lon, s_chinaman$lat), xy = TRUE)

ex_broomfield <- terra::extract(stack_means, data.frame(s_broomfield$lon, s_broomfield$lat))
ex_broomfield_xy <- terra::extract(stack_means, data.frame(s_broomfield$lon, s_broomfield$lat), xy = TRUE)

ex_credlin <- terra::extract(stack_means, data.frame(s_credlin$lon, s_credlin$lat))
ex_credlin_xy <- terra::extract(stack_means, data.frame(s_credlin$lon, s_credlin$lat), xy = TRUE)
```

## Rename the columns and turn them into dates to use for the time series
```{r}
extracts_list <- list(ex_macgillivray, ex_boulder, ex_13124S, ex_agincourt, ex_feather, ex_rib, ex_19138S, ex_chinaman, ex_broomfield, ex_credlin)

names(extracts_list) <- c("MacGillivray Reef", "Boulder Reef", "13124S", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S","Chinaman Reef", "Broomfield Reef", "Credlin Reefs (east)")

for (i in 1:length(extracts_list)){
  # get rid of first column called ID
  extracts_list[[i]] <- select(extracts_list[[i]], -"ID")
  # select one row (because all lines contain the same values) and transpose
  extracts_list[[i]] <- extracts_list[[i]][1,]
  # transpose
  extracts_list[[i]] <- as.data.frame(t(extracts_list[[i]]))
  # turn first row names (years) into a column and call the column "year"
  extracts_list[[i]] <- tibble::rownames_to_column(extracts_list[[i]], "year")
  # convert the year <chr> into a date
  extracts_list[[i]][1]$year <- ymd(sprintf("%s-01-01", extracts_list[[i]][1]$year))
  # log-transform mean_dhw
  extracts_list[[i]][2] <- log10(extracts_list[[i]][2]+1)
  # name the second column "log_mean_dhw"
  names(extracts_list[[i]])[2] <- "log_mean_dhw"
}
# I now have all the coral sites with year and mean dhw in a list
```

# Time Series Analysis
Have mean DHW and mean cover per unit effort (cpue) log-transformed for the time series and the statistics.
```{r}
# zoo time series for mean DHW at all locations
zoo_list_dhw <- list()
dhw_list_ggplot <- list()
for (i in 1:length(extracts_list)){
  name <- paste0(names(extracts_list[i]))
  zoo_list_dhw[[name]] <- zoo(extracts_list[[i]][,2], order.by = extracts_list[[i]][,1], frequency = 1)
  #plot.zoo(zoo_list_dhw[[name]], ylab = "Mean DHW", xlab = "Years") + title(main = names(zoo_list_dhw[i]))
  dhw_list_ggplot[[name]] <- fortify(zoo_list_dhw[[i]], melt = FALSE)
  # rename columns
  names(dhw_list_ggplot[[i]])[1] <- "years"
  names(dhw_list_ggplot[[i]])[2] <- "log_mean_dhw"
  # new column with list name so that I can put data frames together and know where they came from
  dhw_list_ggplot[[i]]$site <- names(dhw_list_ggplot[i])
}

# for facet_wrapping put all data frames into one
dhw_ts_plots <- do.call(rbind,dhw_list_ggplot)

p <- ggplot(dhw_ts_plots, aes(x = years, y = log_mean_dhw, color = factor(site, levels = c("13124S", "MacGillivray Reef", "Boulder Reef", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S", "Credlin Reefs (east)", "Chinaman Reef", "Broomfield Reef")))) +
  geom_point(size = 0.7, alpha = 0.6) +
  geom_line() +
  ylab("Log(Mean DHW)") +
  xlab("Years") +
  theme_classic() +
  ggtitle("Mean Degree Heating Week (DHW) at each location") +
  theme(legend.position = "none", strip.text = element_text(size=12, face = "bold"), axis.title = element_text(size = 14, face = "bold"), plot.title = element_text(hjust = 0.5, face = "bold")) +
  facet_wrap(~factor(site, levels = c("13124S", "MacGillivray Reef", "Boulder Reef", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S", "Credlin Reefs (east)", "Chinaman Reef", "Broomfield Reef")), ncol = 1, scales = "free_y") +
  scale_color_viridis_d(option = "viridis") +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y")

ggsave(p, filename = here("Plots/log_dhw_ts_all_locations.png"), height = 50, width = 30, units = "cm", scale = 0.7)





# zoo time series for log_cpue at all locations
cpue_list <- list(n_macgillivray, n_boulder, n_13124S, c_agincourt, c_feather, c_rib, c_19138S, s_chinaman, s_broomfield, s_credlin)

names(cpue_list) <- c("MacGillivray Reef", "Boulder Reef", "13124S", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S","Chinaman Reef", "Broomfield Reef", "Credlin Reefs (east)")

zoo_list_cpue <- list()
cpue_list_ggplot <- list()
for (i in 1:length(cpue_list)){
  name <- paste0(names(cpue_list[i]))
  zoo_list_cpue[[name]] <- zoo(cpue_list[[i]]$log_cpue, order.by = cpue_list[[i]]$sample_date, frequency = 1)
  #plot.zoo(zoo_list_cpue[[name]], ylab = "Mean DHW", xlab = "Years") + title(main = names(zoo_list_cpue[i]))
  # convert zoo object into data frame to use ggplot
  cpue_list_ggplot[[name]] <- fortify(zoo_list_cpue[[i]], melt = FALSE)
  # rename columns
  names(cpue_list_ggplot[[i]])[1] <- "years"
  names(cpue_list_ggplot[[i]])[2] <- "log_cpue"
  # new column with list name so that I can put data frames together and know where they came from
  cpue_list_ggplot[[i]]$site <- names(cpue_list_ggplot[i])
}

# for facet_wrapping put all data frames into one
cpue_ts_plots <- do.call(rbind,cpue_list_ggplot)

p <- ggplot(cpue_ts_plots, aes(x = years, y = log_cpue, color = factor(site, levels = c( "13124S", "MacGillivray Reef", "Boulder Reef", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S", "Credlin Reefs (east)", "Chinaman Reef", "Broomfield Reef")))) +
  geom_point(size = 0.7, alpha = 0.6) +
  geom_line() +
  ylab("Log(Mean Cover per Unit Effort)") +
  xlab("Years") +
  ggtitle("Mean cover per unit effort at each location") +
  theme_classic() +
  theme(legend.position = "none", strip.text = element_text(size=12, face = "bold"), axis.title = element_text(size = 14, face = "bold"), plot.title = element_text(hjust = 0.5, face = "bold")) +
  facet_wrap(~factor(site, levels = c( "13124S", "MacGillivray Reef", "Boulder Reef", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S", "Credlin Reefs (east)", "Chinaman Reef", "Broomfield Reef")), ncol = 1, scales = "free_y") +
  scale_color_viridis_d(option = "viridis") +
  scale_x_datetime(date_breaks = "2 years", date_labels = "%Y")

ggsave(p, filename = here("Plots/cpue_ts_all_locations.png"), height = 50, width = 30, units = "cm", scale = 0.7)

```

# Combine the two ts_plots dataframes and rename them for linear regression and for plotting together
```{r}
# round up or down to years to make it match with dhw_ts_plots
cpue_ts_plots$years <- round_date(cpue_ts_plots$years, "years")

# bind rows together of cpue_ts_plots and dhw_ts_plots
# less dates in cpue_ts_plots -> left_join to match all the dates from dhw to the ones from cpue
dhw_cpue <- left_join(cpue_ts_plots, dhw_ts_plots)

# plot log_cpue and mean_dhw on top of each other
# how to get scale right? and secondary axis?
lims <- as.POSIXct(strptime(c("1993-01-01", "2021-01-02"), 
                   format = "%Y-%m-%d"))
p <- ggplot(dhw_cpue, aes(x = years, color = factor(site, levels = c( "13124S", "MacGillivray Reef", "Boulder Reef", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S", "Credlin Reefs (east)", "Chinaman Reef", "Broomfield Reef")))) +
  geom_line(aes(y = log_cpue))+
  geom_line(aes(y = log_mean_dhw), color = "red") +
  ylab("Log(Mean Cover per Unit Effort)") +
  xlab("Years") +
  facet_wrap(~factor(site, levels = c( "13124S", "MacGillivray Reef", "Boulder Reef", "Agincourt Reefs (No 1)", "Feather Reef", "Rib Reef", "19138S", "Credlin Reefs (east)", "Chinaman Reef", "Broomfield Reef")), ncol = 2, scales = "free_y") +
  scale_color_viridis_d(option = "viridis") +
  theme_classic() +
  ggtitle("Time Series - Mean DHW and Cover per Unit Effort") +
  theme(legend.position = "none", strip.text = element_text(size=12, face = "bold"), axis.title = element_text(size = 14, face = "bold"), plot.title = element_text(hjust = 0.5, face = "bold", size = 15)) +
  scale_x_datetime(date_breaks = "2 years", date_labels = "%Y", limits = lims) +
  scale_y_continuous(
    sec.axis = sec_axis(~.*0.3, name = expression(bold(Log(Mean~DHW)[red])))) +

# scale between dhw and cpue -> dhw is ~1.5 times bigger than cpue
(max(dhw_cpue$log_mean_dhw) - min(dhw_cpue$log_mean_dhw))*(max(dhw_cpue$log_cpue) - min(dhw_cpue$log_cpue))

ggsave(p, filename = here("Plots/dhw_cpue.png"), height = 70, width = 60, units = "cm", scale = 0.5)
```

# Cross-correlation
Through cross-correlation, you can figure out if there's a lagged correlation between two time series. Cross-correlation can tell you if values of one time series are predictive of the future values of another, i.e. is one time series an indicator for another.

The lag refers to how far the series are offset, and its sign determines which series is shifted.
lag of 2:
  ABCDEFGHIJKLMNOPQRSTUVWXYZ
abcdefghijklmnopqrstuvwxyz
lag of -2:
ABCDEFGHIJKLMNOPQRSTUVWXYZ
  abcdefghijklmnopqrstuvwxyz
```{r}
# zoo_list_dhw contains the time series object for dhw at each location
# zoo_list_cpue contains the time series object for coral cover at each location

# if the vertical lines go over the horizontal dashed line, it's significant
d <- coredata(zoo_list_dhw$`MacGillivray Reef`)
c <- coredata(zoo_list_cpue$`MacGillivray Reef`)
ccf(d, c, main = "DHW vs. CPUE") # non significant

# dashed lines are 95% confidence interval, if over that line, autocorrelation distinguishable from 0
# autocorrelation at lag 0 should be 1 (how does the data correlate with itself? = 1)
acf(c) # some autocorrelation
acf(d) 

d <- coredata(zoo_list_dhw$`Boulder Reef`)
c <- coredata(zoo_list_cpue$`Boulder Reef`)
print(ccf(d, c, main = "DHW vs. CPUE"))
# significant at -7 with 0.538
# this means that the cover data lags 7 years after the dhw data

d <- coredata(zoo_list_dhw$`13124S`)
c <- coredata(zoo_list_cpue$`13124S`)
ccf(d, c, main = "DHW vs. CPUE") # non significant

d <- coredata(zoo_list_dhw$`Agincourt Reefs (No 1)`)
c <- coredata(zoo_list_cpue$`Agincourt Reefs (No 1)`)
ccf(d, c, main = "DHW vs. CPUE") # non significant

d <- coredata(zoo_list_dhw$`Feather Reef`)
c <- coredata(zoo_list_cpue$`Feather Reef`)
ccf(d, c, main = "DHW vs. CPUE") # non significant

d <- coredata(zoo_list_dhw$`Rib Reef`)
c <- coredata(zoo_list_cpue$`Rib Reef`)
ccf(d, c, main = "DHW vs. CPUE") # non significant

d <- coredata(zoo_list_dhw$`19138S`)
c <- coredata(zoo_list_cpue$`19138S`)
ccf(d, c, main = "DHW vs. CPUE") # non significant

d <- coredata(zoo_list_dhw$`Chinaman Reef`)
c <- coredata(zoo_list_cpue$`Chinaman Reef`)
ccf(d, c, main = "DHW vs. CPUE") # non significant

d <- coredata(zoo_list_dhw$`Broomfield Reef`)
c <- coredata(zoo_list_cpue$`Broomfield Reef`)
ccf(d, c, main = "DHW vs. CPUE") # non significant

d <- coredata(zoo_list_dhw$`Credlin Reefs (east)`)
c <- coredata(zoo_list_cpue$`Credlin Reefs (east)`)
print(ccf(d, c, main = "DHW vs. CPUE")) # non significant

```

# COTS and coral trout
```{r}
# ! cots not log transformed
ggplot(n_macgillivray, aes(x = sample_date)) +
  geom_line(aes(y = mean_cots_per_tow), color = "red") +
  geom_line(aes(y = log_cpue)) +
  theme_classic()

ggplot(n_boulder, aes(x = sample_date)) +
  geom_line(aes(y = mean_cots_per_tow), color = "red") +
  geom_line(aes(y = log_cpue)) +
  theme_classic()

ggplot(n_13124S, aes(x = sample_date)) +
  geom_line(aes(y = mean_cots_per_tow), color = "red") +
  geom_line(aes(y = log_cpue)) +
  theme_classic()

ggplot(c_agincourt, aes(x = sample_date)) +
  geom_line(aes(y = mean_cots_per_tow), color = "red") +
  geom_line(aes(y = log_cpue)) +
  theme_classic()

ggplot(c_feather, aes(x = sample_date)) +
  geom_line(aes(y = log_cots_pertow), color = "red") +
  geom_line(aes(y = log_cpue)) +
  theme_classic()

ggplot(c_rib, aes(x = sample_date)) +
  geom_line(aes(y = log_cots_pertow), color = "red") +
  geom_line(aes(y = log_cpue)) +
  theme_classic()

ggplot(c_19138S, aes(x = sample_date)) +
  geom_line(aes(y = log_cots_pertow), color = "red") +
  geom_line(aes(y = log_cpue)) +
  theme_classic()

ggplot(s_chinaman, aes(x = sample_date)) +
  geom_line(aes(y = log_cots_pertow), color = "red") +
  geom_line(aes(y = log_cpue)) +
  theme_classic()

ggplot(s_credlin, aes(x = sample_date)) +
  geom_line(aes(y = log_cots_pertow), color = "red") +
  geom_line(aes(y = log_cpue)) +
  theme_classic()

ggplot(s_broomfield, aes(x = sample_date)) +
  geom_line(aes(y = log_cots_pertow), color = "red") +
  geom_line(aes(y = log_cpue)) +
  theme_classic() # no cots recorded at all
```

# Linear Model and eliminating autocorrelation
Durbin-Watson test and Cochrane Orcutt after [RPubs](https://rpubs.com/apricitea/handling-autocorrelation).
Mean DHW has no significant effect on coral cover in any of the 10 locations.
```{r}
# NORTH ---------------------------------------------------------
lm_mac <- filter(dhw_cpue, site == "MacGillivray Reef")
cor(lm_mac$log_cpue, lm_mac$log_mean_dhw)
m_mac <- lm(log_cpue ~ log_mean_dhw, data = lm_mac)
summary(m_mac)
autoplot(m_mac)
acf(m_mac$residuals)
# Durbin-Watson Test -> autocorrelation does exist as p < 0.05 -> H1: autocorrelation does exist
dwtest(m_mac)

m_mac_co <- cochrane.orcutt(m_mac)
# optimum rho is 0.584059
# now transform the data
rho<- m_mac_co$rho
y.trans<- lm_mac$log_cpue[-1]-lm_mac$log_cpue[-25]*rho # new log_cpue
x.trans<- lm_mac$log_mean_dhw[-1]-lm_mac$log_mean_dhw[-25]*rho # new log_mean_dhw
mac_modelcorho<- lm(y.trans~x.trans)

# now Durbin-Watson test again
dwtest(mac_modelcorho) # p > 0.05 -> H0 true = there is no autocorrelation anymore

# summary of lm again
summary(mac_modelcorho)




lm_bou <- filter(dhw_cpue, site == "Boulder Reef")
m_bou <- lm(log_cpue ~ log_mean_dhw, data = lm_bou)
summary(m_bou)
dwtest(m_bou) # no autocorrelation
cor(lm_bou$log_cpue, lm_bou$log_mean_dhw)


lm_13 <- filter(dhw_cpue, site == "13124S")
m_13 <- lm(log_cpue ~ log_mean_dhw, data = lm_13)
summary(m_13)
autoplot(m_13)
dwtest(m_13) # no autocorrelation
cor(lm_13$log_cpue, lm_13$log_mean_dhw)

# CENTRAL ---------------------------------------------------------
lm_agi <- filter(dhw_cpue, site == "Agincourt Reefs (No 1)")
m_agi <- lm(log_cpue ~ log_mean_dhw, data = lm_agi)
summary(m_agi)

dwtest(m_agi) # autocorrelation
m_agi_co <- cochrane.orcutt(m_agi)
rho<- m_agi_co$rho
y.trans<- lm_agi$log_cpue[-1]-lm_agi$log_cpue[-28]*rho # new log_cpue
x.trans<- lm_agi$log_mean_dhw[-1]-lm_agi$log_mean_dhw[-28]*rho # new log_mean_dhw
agi_modelcorho<- lm(y.trans~x.trans)

# now Durbin-Watson test again
dwtest(agi_modelcorho) # p > 0.05 -> H0 true = there is no autocorrelation anymore
summary(agi_modelcorho)

cor(lm_agi$log_cpue, lm_agi$log_mean_dhw)


lm_fea <- filter(dhw_cpue, site == "Feather Reef")
m_fea <- lm(log_cpue ~ log_mean_dhw, data = lm_fea)
summary(m_fea)
dwtest(m_fea) # autocorrelation
m_fea_co <- cochrane.orcutt(m_fea)
rho<- m_fea_co$rho
y.trans<- lm_fea$log_cpue[-1]-lm_fea$log_cpue[-25]*rho # new log_cpue
x.trans<- lm_fea$log_mean_dhw[-1]-lm_fea$log_mean_dhw[-25]*rho # new log_mean_dhw
fea_modelcorho<- lm(y.trans~x.trans)

# now Durbin-Watson test again
dwtest(fea_modelcorho) # p > 0.05 -> H0 true = there is no autocorrelation anymore
summary(fea_modelcorho)

cor(lm_fea$log_cpue, lm_fea$log_mean_dhw)

lm_rib <- filter(dhw_cpue, site == "Rib Reef")
m_rib <- lm(log_cpue ~ log_mean_dhw, data = lm_rib)
summary(m_rib)
dwtest(m_rib) # autocorrelation
m_rib_co <- cochrane.orcutt(m_rib)
rho<- m_rib_co$rho
y.trans<- lm_rib$log_cpue[-1]-lm_rib$log_cpue[-28]*rho # new log_cpue
x.trans<- lm_rib$log_mean_dhw[-1]-lm_rib$log_mean_dhw[-28]*rho # new log_mean_dhw
rib_modelcorho<- lm(y.trans~x.trans)

# now Durbin-Watson test again
dwtest(rib_modelcorho) # p > 0.05 -> H0 true = there is no autocorrelation anymore
summary(rib_modelcorho)

cor(lm_rib$log_cpue, lm_rib$log_mean_dhw)

lm_19 <- filter(dhw_cpue, site == "19138S")
m_19 <- lm(log_cpue ~ log_mean_dhw, data = lm_19)
summary(m_19)
dwtest(m_19) # no autocorrelation

cor(lm_19$log_cpue, lm_19$log_mean_dhw)

# SOUTH ---------------------------------------------------------
lm_cre <- filter(dhw_cpue, site == "Credlin Reefs (east)")
m_cre <- lm(log_cpue ~ log_mean_dhw, data = lm_cre)
summary(m_cre)
dwtest(m_cre) # autocorrelation
m_cre_co <- cochrane.orcutt(m_cre)
rho<- m_cre_co$rho
y.trans<- lm_cre$log_cpue[-1]-lm_cre$log_cpue[-21]*rho # new log_cpue
x.trans<- lm_cre$log_mean_dhw[-1]-lm_cre$log_mean_dhw[-21]*rho # new log_mean_dhw
cre_modelcorho<- lm(y.trans~x.trans)

# now Durbin-Watson test again
dwtest(cre_modelcorho) # p > 0.05 -> H0 true = there is no autocorrelation anymore
summary(cre_modelcorho)

cor(lm_cre$log_cpue, lm_cre$log_mean_dhw)

lm_chi <- filter(dhw_cpue, site == "Chinaman Reef")
m_chi <- lm(log_cpue ~ log_mean_dhw, data = lm_chi)
summary(m_chi)
dwtest(m_chi) # autocorrelation

m_chi_co <- cochrane.orcutt(m_chi)
rho<- m_chi_co$rho
y.trans<- lm_chi$log_cpue[-1]-lm_chi$log_cpue[-28]*rho # new log_cpue
x.trans<- lm_chi$log_mean_dhw[-1]-lm_chi$log_mean_dhw[-28]*rho # new log_mean_dhw
chi_modelcorho<- lm(y.trans~x.trans)

# now Durbin-Watson test again
dwtest(chi_modelcorho) # p > 0.05 -> H0 true = there is no autocorrelation anymore
summary(chi_modelcorho)

cor(lm_chi$log_cpue, lm_chi$log_mean_dhw)

lm_bro <- filter(dhw_cpue, site == "Broomfield Reef")
m_bro <- lm(log_cpue ~ log_mean_dhw, data = lm_bro)
summary(m_bro)
dwtest(m_bro) # autocorrelation


m_bro_co <- cochrane.orcutt(m_bro)
rho<- m_bro_co$rho
y.trans<- lm_bro$log_cpue[-1]-lm_bro$log_cpue[-27]*rho # new log_cpue
x.trans<- lm_bro$log_mean_dhw[-1]-lm_bro$log_mean_dhw[-27]*rho # new log_mean_dhw
bro_modelcorho<- lm(y.trans~x.trans)


# now Durbin-Watson test again
dwtest(bro_modelcorho) # p > 0.05 -> H0 true = there is no autocorrelation anymore
summary(bro_modelcorho)

cor(lm_bro$log_cpue, lm_bro$log_mean_dhw)
```

 
 
 